{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b45b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 16:48:12,384\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-09-02 16:48:13,026\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from gymnasium.spaces import Box, Discrete, Space\n",
    "from poke_env.battle import AbstractBattle, Battle\n",
    "from poke_env.environment import SingleAgentWrapper, SinglesEnv\n",
    "from poke_env.player import RandomPlayer\n",
    "from ray.rllib.algorithms import PPOConfig\n",
    "from ray.rllib.core import Columns\n",
    "from ray.rllib.core.rl_module import RLModuleSpec\n",
    "from ray.rllib.core.rl_module.apis.value_function_api import ValueFunctionAPI\n",
    "from ray.rllib.core.rl_module.torch import TorchRLModule\n",
    "from ray.rllib.env import ParallelPettingZooEnv\n",
    "from ray.tune.registry import register_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d86a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleEnv(SinglesEnv[npt.NDArray[np.float32]]):\n",
    "    LOW = [-1, -1, -1, -1, 0, 0, 0, 0, 0, 0]\n",
    "    HIGH = [3, 3, 3, 3, 4, 4, 4, 4, 1, 1]\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.observation_spaces = {\n",
    "            agent: Box(\n",
    "                np.array(self.LOW, dtype=np.float32),\n",
    "                np.array(self.HIGH, dtype=np.float32),\n",
    "                dtype=np.float32,\n",
    "            )\n",
    "            for agent in self.possible_agents\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def create_multi_agent_env(cls, config: Dict[str, Any]) -> ParallelPettingZooEnv:\n",
    "        env = cls(\n",
    "            battle_format=config[\"battle_format\"],\n",
    "            log_level=25,\n",
    "            open_timeout=None,\n",
    "            strict=False,\n",
    "        )\n",
    "        return ParallelPettingZooEnv(env)\n",
    "\n",
    "    @classmethod\n",
    "    def create_single_agent_env(cls, config: Dict[str, Any]) -> SingleAgentWrapper:\n",
    "        env = cls(\n",
    "            battle_format=config[\"battle_format\"],\n",
    "            log_level=25,\n",
    "            open_timeout=None,\n",
    "            strict=False,\n",
    "        )\n",
    "        opponent = RandomPlayer()\n",
    "        return SingleAgentWrapper(env, opponent)\n",
    "\n",
    "    def calc_reward(self, battle) -> float:\n",
    "        return self.reward_computing_helper(\n",
    "            battle, fainted_value=2.0, hp_value=1.0, victory_value=30.0\n",
    "        )\n",
    "\n",
    "    def embed_battle(self, battle: AbstractBattle):\n",
    "        assert isinstance(battle, Battle)\n",
    "        # -1 indicates that the move does not have a base power\n",
    "        # or is not available\n",
    "        moves_base_power = -np.ones(4)\n",
    "        moves_dmg_multiplier = np.ones(4)\n",
    "        for i, move in enumerate(battle.available_moves):\n",
    "            moves_base_power[i] = (\n",
    "                move.base_power / 100\n",
    "            )  # Simple rescaling to facilitate learning\n",
    "            if battle.opponent_active_pokemon is not None:\n",
    "                moves_dmg_multiplier[i] = move.type.damage_multiplier(\n",
    "                    battle.opponent_active_pokemon.type_1,\n",
    "                    battle.opponent_active_pokemon.type_2,\n",
    "                    type_chart=battle.opponent_active_pokemon._data.type_chart,\n",
    "                )\n",
    "\n",
    "        # We count how many pokemons have fainted in each team\n",
    "        fainted_mon_team = len([mon for mon in battle.team.values() if mon.fainted]) / 6\n",
    "        fainted_mon_opponent = (\n",
    "            len([mon for mon in battle.opponent_team.values() if mon.fainted]) / 6\n",
    "        )\n",
    "\n",
    "        # Final vector with 10 components\n",
    "        final_vector = np.concatenate(\n",
    "            [\n",
    "                moves_base_power,\n",
    "                moves_dmg_multiplier,\n",
    "                [fainted_mon_team, fainted_mon_opponent],\n",
    "            ]\n",
    "        )\n",
    "        return np.float32(final_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b37201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCriticModule(TorchRLModule, ValueFunctionAPI):\n",
    "    def __init__(\n",
    "        self,\n",
    "        observation_space: Space,\n",
    "        action_space: Space,\n",
    "        inference_only: bool,\n",
    "        model_config: Dict[str, Any],\n",
    "        catalog_class: Any,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            observation_space=observation_space,\n",
    "            action_space=action_space,\n",
    "            inference_only=inference_only,\n",
    "            model_config=model_config,\n",
    "            catalog_class=catalog_class,\n",
    "        )\n",
    "        self.model = nn.Linear(10, 100)\n",
    "        self.actor = nn.Linear(100, 26)\n",
    "        self.critic = nn.Linear(100, 1)\n",
    "\n",
    "    def _forward(self, batch: Dict[str, Any], **kwargs) -> Dict[str, Any]:\n",
    "        obs = batch[Columns.OBS]\n",
    "        embeddings = self.model(obs)\n",
    "        logits = self.actor(embeddings)\n",
    "        return {Columns.EMBEDDINGS: embeddings, Columns.ACTION_DIST_INPUTS: logits}\n",
    "\n",
    "    def compute_values(\n",
    "        self, batch: Dict[str, Any], embeddings: Optional[torch.Tensor] = None\n",
    "    ) -> torch.Tensor:\n",
    "        if embeddings is None:\n",
    "            embeddings = self.model(batch[Columns.OBS])\n",
    "        return self.critic(embeddings).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c257380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_agent_train():\n",
    "    register_env(\"showdown\", ExampleEnv.create_single_agent_env)\n",
    "    config = PPOConfig()\n",
    "    config = config.environment(\n",
    "        \"showdown\",\n",
    "        env_config={\"battle_format\": \"gen9randombattle\"},\n",
    "        disable_env_checking=True,\n",
    "    )\n",
    "    config = config.learners(num_learners=1)\n",
    "    config = config.rl_module(\n",
    "        rl_module_spec=RLModuleSpec(\n",
    "            module_class=ActorCriticModule,\n",
    "            observation_space=Box(\n",
    "                np.array(ExampleEnv.LOW, dtype=np.float32),\n",
    "                np.array(ExampleEnv.HIGH, dtype=np.float32),\n",
    "                dtype=np.float32,\n",
    "            ),\n",
    "            action_space=Discrete(26),\n",
    "            model_config={},\n",
    "        )\n",
    "    )\n",
    "    config = config.training(\n",
    "        gamma=0.99, lr=1e-3, train_batch_size=1024, num_epochs=10, minibatch_size=64\n",
    "    )\n",
    "    algo = config.build_algo()\n",
    "    algo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc6bdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_agent_train():\n",
    "    register_env(\"showdown\", ExampleEnv.create_multi_agent_env)\n",
    "    config = PPOConfig()\n",
    "    config = config.environment(\n",
    "        \"showdown\",\n",
    "        env_config={\"battle_format\": \"gen9randombattle\"},\n",
    "        disable_env_checking=True,\n",
    "    )\n",
    "    config = config.learners(num_learners=1)\n",
    "    config = config.multi_agent(\n",
    "        policies={\"p1\"},\n",
    "        policy_mapping_fn=lambda agent_id, ep_type: \"p1\",\n",
    "        policies_to_train=[\"p1\"],\n",
    "    )\n",
    "    config = config.rl_module(\n",
    "        rl_module_spec=RLModuleSpec(\n",
    "            module_class=ActorCriticModule,\n",
    "            observation_space=Box(\n",
    "                np.array(ExampleEnv.LOW, dtype=np.float32),\n",
    "                np.array(ExampleEnv.HIGH, dtype=np.float32),\n",
    "                dtype=np.float32,\n",
    "            ),\n",
    "            action_space=Discrete(26),\n",
    "            model_config={},\n",
    "        )\n",
    "    )\n",
    "    config = config.training(\n",
    "        gamma=0.99, lr=1e-3, train_batch_size=1024, num_epochs=10, minibatch_size=64\n",
    "    )\n",
    "    algo = config.build_algo()\n",
    "    algo.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "767c5d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 16:48:14,264\tWARNING algorithm_config.py:5045 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:520: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-09-02 16:48:15,444\tINFO worker.py:1951 -- Started a local Ray instance.\n",
      "[2025-09-02 16:48:16,739 E 173109 173109] core_worker.cc:2246: Actor with class name: 'SingleAgentEnvRunner' and ID: 'da7ccc6e780410d9c8b25c8f01000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173432)\u001b[0m 2025-09-02 16:48:19,272 - RandomPlayer 1 - CRITICAL - Error message received: |nametaken|RandomPlayer 1|Someone is already using the name \"RandomPlayer 1\".\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173432)\u001b[0m 2025-09-02 16:48:19,273 - RandomPlayer 1 - ERROR - Unhandled exception raised while handling message:\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173432)\u001b[0m |nametaken|RandomPlayer 1|Someone is already using the name \"RandomPlayer 1\".\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173432)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173432)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/poke_env/ps_client/ps_client.py\", line 170, in _handle_message\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173432)\u001b[0m     raise ShowdownException(\"Error message received: %s\", message)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173432)\u001b[0m poke_env.exceptions.ShowdownException: ('Error message received: %s', '|nametaken|RandomPlayer 1|Someone is already using the name \"RandomPlayer 1\".')\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173432)\u001b[0m 2025-09-02 16:48:19,379\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-09-02 16:48:19,583\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-09-02 16:48:19,621\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 16:48:23,581\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m free(): double free detected in tcache 2\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m *** SIGABRT received at time=1756824507 on cpu 2 ***\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m PC: @     0x7fc34a29eb2c  (unknown)  pthread_kill\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc34a245330  347840160  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc34a24527e         32  raise\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc34a2288ff        192  abort\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc34a2297b6        288  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc34a2a8ff5         16  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc34a2ab55f         80  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc34a2addae         64  cfree\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc0cd515e45         48  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc0cd529889         48  (unknown)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173434)\u001b[0m 2025-09-02 16:48:19,259 - RandomPlayer 1 - CRITICAL - Error message received: |nametaken|RandomPlayer 1|Someone is already using the name \"RandomPlayer 1\".\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173434)\u001b[0m 2025-09-02 16:48:19,259 - RandomPlayer 1 - ERROR - Unhandled exception raised while handling message:\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173434)\u001b[0m |nametaken|RandomPlayer 1|Someone is already using the name \"RandomPlayer 1\".\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173434)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173434)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/poke_env/ps_client/ps_client.py\", line 170, in _handle_message\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173434)\u001b[0m     raise ShowdownException(\"Error message received: %s\", message)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=173434)\u001b[0m poke_env.exceptions.ShowdownException: ('Error message received: %s', '|nametaken|RandomPlayer 1|Someone is already using the name \"RandomPlayer 1\".')\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m 2025-09-02 16:48:22,286\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc0cd353bcd         64  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc0cd354fc5         80  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc0cd315264        288  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc0cd3ae812        208  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc0cd33a71b         32  cuInit\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc2cc434a76       1088  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc2cc439638        320  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc34a2a1ed3        112  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc2cc488ed9         48  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc2cc44d99a        256  cudaGetDeviceCount\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m     @     0x7fc2d40c1e07  (unknown)  c10::cuda::(anonymous namespace)::device_count_impl()\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,805 E 173437 173437] logging.cc:474: *** SIGABRT received at time=1756824507 on cpu 2 ***\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,805 E 173437 173437] logging.cc:474: PC: @     0x7fc34a29eb2c  (unknown)  pthread_kill\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,805 E 173437 173437] logging.cc:474:     @     0x7fc34a245330  347840160  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,805 E 173437 173437] logging.cc:474:     @     0x7fc34a24527e         32  raise\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,805 E 173437 173437] logging.cc:474:     @     0x7fc34a2288ff        192  abort\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,805 E 173437 173437] logging.cc:474:     @     0x7fc34a2297b6        288  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,805 E 173437 173437] logging.cc:474:     @     0x7fc34a2a8ff5         16  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,805 E 173437 173437] logging.cc:474:     @     0x7fc34a2ab55f         80  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,805 E 173437 173437] logging.cc:474:     @     0x7fc34a2addae         64  cfree\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,825 E 173437 173437] logging.cc:474:     @     0x7fc0cd515e45         48  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,835 E 173437 173437] logging.cc:474:     @     0x7fc0cd529889         48  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,841 E 173437 173437] logging.cc:474:     @     0x7fc0cd353bcd         64  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,870 E 173437 173437] logging.cc:474:     @     0x7fc0cd354fc5         80  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,907 E 173437 173437] logging.cc:474:     @     0x7fc0cd315264        288  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,946 E 173437 173437] logging.cc:474:     @     0x7fc0cd3ae812        208  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,946 E 173437 173437] logging.cc:474:     @     0x7fc0cd33a71b         32  cuInit\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,946 E 173437 173437] logging.cc:474:     @     0x7fc2cc434a76       1088  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,946 E 173437 173437] logging.cc:474:     @     0x7fc2cc439638        320  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,947 E 173437 173437] logging.cc:474:     @     0x7fc34a2a1ed3        112  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,947 E 173437 173437] logging.cc:474:     @     0x7fc2cc488ed9         48  (unknown)\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,947 E 173437 173437] logging.cc:474:     @     0x7fc2cc44d99a        256  cudaGetDeviceCount\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m [2025-09-02 16:48:27,947 E 173437 173437] logging.cc:474:     @     0x7fc2d40c1e07  (unknown)  c10::cuda::(anonymous namespace)::device_count_impl()\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m Fatal Python error: Aborted\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m \n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m Stack (most recent call first):\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/torch/autograd/graph.py\", line 829 in _engine_run_backward\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py\", line 354 in backward\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/torch/_tensor.py\", line 647 in backward\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/rllib/core/learner/torch/torch_learner.py\", line 190 in compute_gradients\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/util/tracing/tracing_helper.py\", line 461 in _resume_span\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/rllib/core/learner/torch/torch_learner.py\", line 156 in _uncompiled_update\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/util/tracing/tracing_helper.py\", line 461 in _resume_span\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/rllib/core/learner/torch/torch_learner.py\", line 520 in _update\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/util/tracing/tracing_helper.py\", line 461 in _resume_span\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/rllib/core/learner/learner.py\", line 1076 in update\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/util/tracing/tracing_helper.py\", line 461 in _resume_span\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/_private/function_manager.py\", line 689 in actor_method_executor\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/_private/worker.py\", line 984 in main_loop\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m   File \"/home/bapti/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/_private/workers/default_worker.py\", line 323 in <module>\n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m \n",
      "\u001b[36m(_WrappedExecutable pid=173437)\u001b[0m Extension modules: psutil._psutil_linux, psutil._psutil_posix, msgpack._cmsgpack, google._upb._message, yaml._yaml, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, ray._raylet, numpy._core._multiarray_umath, numpy._core._multiarray_tests, numpy.linalg._umath_linalg, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, lz4._version, lz4.frame._frame, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, pyarrow._parquet, scipy._lib._ccallback_c, scipy.signal._sigtools, scipy.linalg._fblas, scipy.linalg._flapack, _cyutility, scipy._cyutility, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_schur_sqrtm, scipy.linalg._matfuncs_expm, scipy.linalg._linalg_pythran, scipy.linalg.cython_blas, scipy.linalg._decomp_update, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.special._ufuncs_cxx, scipy.special._ellip_harm_2, scipy.special._special_ufuncs, scipy.special._gufuncs, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy._lib._uarray._uarray, scipy.signal._max_len_seq_inner, scipy.signal._upfirdn_apply, scipy.signal._spline, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._hausdorff, scipy.spatial._distance_wrap, scipy.spatial.transform._rotation, scipy.spatial.transform._rigid_transform, scipy.interpolate._fitpack, scipy.interpolate._dfitpack, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.linalg._propack._spropack, scipy.sparse.linalg._propack._dpropack, scipy.sparse.linalg._propack._cpropack, scipy.sparse.linalg._propack._zpropack, scipy.optimize._group_columns, scipy.optimize._trlib._trlib, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._slsqplib, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.linalg._decomp_interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.optimize._direct, scipy.interpolate._dierckx, scipy.interpolate._ppoly, scipy.interpolate._interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy.ndimage._nd_image, scipy.ndimage._rank_filter_1d, _ni_label, scipy.ndimage._ni_label, scipy.signal._sosfilt, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.integrate._lsoda, scipy.special.cython_special, scipy.stats._stats, scipy.stats._biasedurn, scipy.stats._stats_pythran, scipy.stats._levy_stable.levyst, scipy.stats._ansari_swilk_statistics, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._rcont.rcont, scipy.stats._qmvnt_cy, scipy.signal._peak_finding_utils, pyarrow._json (total: 174)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msingle_agent_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#multi_agent_train()\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36msingle_agent_train\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     22\u001b[39m config = config.training(\n\u001b[32m     23\u001b[39m     gamma=\u001b[32m0.99\u001b[39m, lr=\u001b[32m1e-3\u001b[39m, train_batch_size=\u001b[32m1024\u001b[39m, num_epochs=\u001b[32m10\u001b[39m, minibatch_size=\u001b[32m64\u001b[39m\n\u001b[32m     24\u001b[39m )\n\u001b[32m     25\u001b[39m algo = config.build_algo()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43malgo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/tune/trainable/trainable.py:328\u001b[39m, in \u001b[36mTrainable.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    326\u001b[39m start = time.time()\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    330\u001b[39m     skipped = skip_exceptions(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:1035\u001b[39m, in \u001b[36mAlgorithm.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1030\u001b[39m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[32m   1031\u001b[39m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[32m   1032\u001b[39m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[32m   1033\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1034\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.enable_env_runner_and_connector_v2:\n\u001b[32m-> \u001b[39m\u001b[32m1035\u001b[39m         train_results, train_iter_ctx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1037\u001b[39m         (\n\u001b[32m   1038\u001b[39m             train_results,\n\u001b[32m   1039\u001b[39m             train_iter_ctx,\n\u001b[32m   1040\u001b[39m         ) = \u001b[38;5;28mself\u001b[39m._run_one_training_iteration_old_api_stack()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:3396\u001b[39m, in \u001b[36mAlgorithm._run_one_training_iteration\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3394\u001b[39m \u001b[38;5;66;03m# Try to train one step.\u001b[39;00m\n\u001b[32m   3395\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metrics.log_time((TIMERS, TRAINING_STEP_TIMER)):\n\u001b[32m-> \u001b[39m\u001b[32m3396\u001b[39m     training_step_return_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3397\u001b[39m     has_run_once = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3399\u001b[39m \u001b[38;5;66;03m# On the new API stack, results should NOT be returned anymore as\u001b[39;00m\n\u001b[32m   3400\u001b[39m \u001b[38;5;66;03m# a dict, but purely logged through the `MetricsLogger` API. This\u001b[39;00m\n\u001b[32m   3401\u001b[39m \u001b[38;5;66;03m# way, we make sure to never miss a single stats/counter/timer\u001b[39;00m\n\u001b[32m   3402\u001b[39m \u001b[38;5;66;03m# when calling `self.training_step()` more than once within the same\u001b[39;00m\n\u001b[32m   3403\u001b[39m \u001b[38;5;66;03m# iteration.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/rllib/algorithms/ppo/ppo.py:425\u001b[39m, in \u001b[36mPPO.training_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# Perform a learner update step on the collected episodes.\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metrics.log_time((TIMERS, LEARNER_UPDATE_TIMER)):\n\u001b[32m--> \u001b[39m\u001b[32m425\u001b[39m     learner_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlearner_group\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m            \u001b[49m\u001b[43mNUM_ENV_STEPS_SAMPLED_LIFETIME\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpeek\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mENV_RUNNER_RESULTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_ENV_STEPS_SAMPLED_LIFETIME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mminibatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminibatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle_batch_per_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshuffle_batch_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    438\u001b[39m     \u001b[38;5;28mself\u001b[39m.metrics.aggregate(learner_results, key=LEARNER_RESULTS)\n\u001b[32m    440\u001b[39m \u001b[38;5;66;03m# Update weights - after learning on the local worker - on all remote\u001b[39;00m\n\u001b[32m    441\u001b[39m \u001b[38;5;66;03m# workers.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/rllib/core/learner/learner_group.py:384\u001b[39m, in \u001b[36mLearnerGroup.update\u001b[39m\u001b[34m(self, batch, batches, batch_refs, episodes, episodes_refs, data_iterators, training_data, timesteps, async_update, return_state, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m         \u001b[38;5;28mself\u001b[39m._ts_dropped += factor * dropped\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# Sync updates.\u001b[39;00m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_worker_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforeach_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremote_call_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    389\u001b[39m results = \u001b[38;5;28mself\u001b[39m._get_results(results)\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/rllib/utils/actor_manager.py:461\u001b[39m, in \u001b[36mFaultTolerantActorManager.foreach_actor\u001b[39m\u001b[34m(self, func, kwargs, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[39m\n\u001b[32m    454\u001b[39m remote_calls = \u001b[38;5;28mself\u001b[39m._call_actors(\n\u001b[32m    455\u001b[39m     func=func,\n\u001b[32m    456\u001b[39m     kwargs=kwargs,\n\u001b[32m    457\u001b[39m     remote_actor_ids=remote_actor_ids,\n\u001b[32m    458\u001b[39m )\n\u001b[32m    460\u001b[39m \u001b[38;5;66;03m# Collect remote request results (if available given timeout and/or errors).\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m _, remote_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetch_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m remote_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/rllib/utils/actor_manager.py:839\u001b[39m, in \u001b[36mFaultTolerantActorManager._fetch_result\u001b[39m\u001b[34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[39m\n\u001b[32m    836\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m remote_calls:\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [], RemoteCallResults()\n\u001b[32m--> \u001b[39m\u001b[32m839\u001b[39m readies, _ = \u001b[43mray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make sure remote results are fetched locally in parallel.\u001b[39;49;00m\n\u001b[32m    844\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[38;5;66;03m# Remote data should already be fetched to local object store at this point.\u001b[39;00m\n\u001b[32m    848\u001b[39m remote_results = RemoteCallResults()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/_private/auto_init_hook.py:22\u001b[39m, in \u001b[36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mauto_init_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     21\u001b[39m     auto_init_ray()\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/_private/client_mode_hook.py:104\u001b[39m, in \u001b[36mclient_mode_hook.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m func.\u001b[34m__name__\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33minit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[32m    103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func.\u001b[34m__name__\u001b[39m)(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/blegeron/pokemon/poke-agent/.venv/lib/python3.12/site-packages/ray/_private/worker.py:3113\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(ray_waitables, num_returns, timeout, fetch_local)\u001b[39m\n\u001b[32m   3111\u001b[39m timeout = timeout \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m10\u001b[39m**\u001b[32m6\u001b[39m\n\u001b[32m   3112\u001b[39m timeout_milliseconds = \u001b[38;5;28mint\u001b[39m(timeout * \u001b[32m1000\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3113\u001b[39m ready_ids, remaining_ids = \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcore_worker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3114\u001b[39m \u001b[43m    \u001b[49m\u001b[43mray_waitables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_returns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_milliseconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfetch_local\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3118\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ready_ids, remaining_ids\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpython/ray/_raylet.pyx:3486\u001b[39m, in \u001b[36mray._raylet.CoreWorker.wait\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpython/ray/includes/common.pxi:96\u001b[39m, in \u001b[36mray._raylet.check_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "single_agent_train()\n",
    "#multi_agent_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poke-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
